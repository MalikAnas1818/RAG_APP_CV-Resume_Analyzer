{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dywUrqiQ5cee",
        "outputId": "5c1e245d-9b28-4d34-afbd-a71f16d96b4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXo-0cpxPe4E",
        "outputId": "a9372838-ff46-431b-94e5-e7cb6732cfc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.5/305.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.67)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.26)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.4)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain-community-0.3.27 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain tiktoken pypdf sentence_transformers InstructorEmbedding faiss-cpu\n",
        "!pip install -U langchain-community\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niM66ZggG65z",
        "outputId": "82dba3c0-1acc-4497-aae2-4c520a726e6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/130.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ3JbuD-KAy5",
        "outputId": "786c700e-4b91-41d9-ef50-d704cfbe6fc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.1.1\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m124.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.26.3\n"
          ]
        }
      ],
      "source": [
        "!pip install -U pip\n",
        "!pip install -U pymupdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K85z-TCxQtjr"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "import os\n",
        "from langchain_community.document_loaders import DirectoryLoader, PyMuPDFLoader\n",
        "from langchain.schema import Document\n",
        "from dotenv import load_dotenv\n",
        "from collections import defaultdict\n",
        "from typing import List\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from pydantic import BaseModel, Field, field_validator\n",
        "from typing import List, Optional\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BON7Zv-0Gnz9"
      },
      "outputs": [],
      "source": [
        "def get_files(directory_path='/content/drive/MyDrive/Resume CV_Uploaded/'):\n",
        "    loader = DirectoryLoader(\n",
        "        path=directory_path,\n",
        "        loader_cls=PyMuPDFLoader,   # ✅ No parentheses\n",
        "        show_progress=True,\n",
        "        glob=\"**/*.pdf\",\n",
        "        use_multithreading=True\n",
        "    )\n",
        "    docs = loader.load()\n",
        "    return docs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXP32oFmIs_Y",
        "outputId": "db5df614-f395-47f4-d762-3451893d93b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 13.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MUHAMMAD ANIS FASEEL\n",
            "MUHAMMAD ANIS FASEEL\n",
            "MUHAMMAD ANIS FASEEL\n",
            "Sultan town  (Near by Ali town Station), Lahore\n",
            "malikanas4737@gmail.com | +923166461053\n",
            "AI engineer with hands-on experience in Generative AI, Machine Learning, and Data Analysis. Skilled at building simple\n",
            "AI models, working with Large Language Models (LLMs), and understanding data to improve business tasks.\n",
            "Comfortable using tools like Python, TensorFlow, scikit-learn, and creating visual charts for data analysis. Always eager\n",
            "to learn new tools and use AI to solve real-world problems.\n",
            "University of South Asia, Lahore \n",
            "Bachelor of Software Engineering\n",
            "Related Coursework: Database Systems, Computer Science, Operations Management, Management, Business\n",
            "Software Development, AI And Machine Learning\n",
            "GPA: 3.00/4.00\n",
            "EDUCATION\n",
            "   Laptop Price Prediction Using Machine Learning\n",
            "Developed a Machine Learning model to predict laptop prices based on features such as brand, specifications, and\n",
            "other relevant attributes. Utilized regression algorithms to analyze historical data and generate accurate price\n",
            "forecasts. Leveraged Python, pandas, and scikit-learn to build and evaluate the model.\n",
            "EXPERIEANCE (ACADMEMIC & PROJECTS)\n",
            "Machine Learning Intern (Self-Initiated Projects)\n",
            "Developed a Laptop Price Prediction Model using Python and Scikit-learn.\n",
            "Developed a Healthcare Diagnosis Prediction Model using Python, Scikit-learn and Streamlit.\n",
            "Collected and preprocessed real estate data, applied regression algorithms, and optimized model preformance.\n",
            "Gained hand-on experience in data analysis, model training, and evaluation techniques.\n",
            "Generative AI ( Freelancing Projects)\n",
            "Developed a Generative AI-based chatbot for WhatsApp using for Langchain Large Language Model (LLM)\n",
            "Build a Medical AI chatbot using for Langchain Model Groq\n",
            "Gained hand-on experience in LLM, Langchain, and LangGraph.\n",
            "AREA OF EXPERTISE\n",
            "Generative AI\n",
            "Machine Learning\n",
            "Deep Learning\n",
            "NLP\n",
            "Key Achievements\n",
            "GENERATIVE AI ENGINEER\n",
            "Language\n",
            "English\n",
            "Urdu\n",
            "French\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "docs = get_files()\n",
        "print(docs[0].page_content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3yGxiDRIt_g"
      },
      "outputs": [],
      "source": [
        "def merge_pages(docs):\n",
        "  combined_texts=defaultdict(str)\n",
        "  for doc in docs:\n",
        "    source=doc.metadata.get(\"source\",\"unknown\")\n",
        "    combined_texts[source] += doc.page_content.strip() + \"\\n\"\n",
        "    merged_docs = [\n",
        "          Document(page_content=text, metadata={\"source\": source})\n",
        "          for source, text in combined_texts.items()\n",
        "      ]\n",
        "  print(f\"Length of the Merge data {len(merged_docs)}\")\n",
        "  return merged_docs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYYHAhmHMAhP",
        "outputId": "944cddd6-1c6a-4c8e-ca19-730be7a562e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of the Merge data 3\n"
          ]
        }
      ],
      "source": [
        "merged_docs = merge_pages(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAeXTdLKLTbo",
        "outputId": "88ec13b1-f7e6-4de6-e6c7-42e44e27b086"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(merged_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EesfdIyeMe25"
      },
      "outputs": [],
      "source": [
        "def get_embedding(merged_docs):\n",
        "  embedding=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "  vector_store=FAISS.from_documents(merged_docs,embedding)\n",
        "  return vector_store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkwJGvGyGDuL"
      },
      "outputs": [],
      "source": [
        "  # Convert distance to similarity score\n",
        "  def distance_to_score(distance: float) -> float:\n",
        "      \"\"\"Convert L2 distance to a normalized similarity score (0–100%)\"\"\"\n",
        "      similarity = 1 / (1 + distance)         # Normalized between 0 and 1\n",
        "      return round(similarity * 100, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5fMzUwOGm9r"
      },
      "outputs": [],
      "source": [
        "    def ret_chain(vector_store):\n",
        "        retriever_chain = RunnableLambda(\n",
        "            lambda query: [\n",
        "                _add_score_to_doc(doc, score)\n",
        "                for doc, score in vector_store.similarity_search_with_score(query)\n",
        "            ]\n",
        "        )\n",
        "        return retriever_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uaiO1CPHfjZ"
      },
      "outputs": [],
      "source": [
        "      def _add_score_to_doc(doc: Document, score: float) -> Document:\n",
        "          score_percent = distance_to_score(score)\n",
        "          doc.metadata[\"score_percent\"] = score_percent\n",
        "          doc.metadata[\"distance\"] = score\n",
        "          return doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kU1CFpz6Hzbk"
      },
      "outputs": [],
      "source": [
        "def label_score_by_distance(distance: float) -> str:\n",
        "    if distance <= 0.8:\n",
        "        return \"Strong match\"\n",
        "    elif distance <= 1.2:\n",
        "        return \"Moderate match\"\n",
        "    else:\n",
        "        return \"Weak match\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hay4bZ16H8Ca"
      },
      "outputs": [],
      "source": [
        "class Education(BaseModel):\n",
        "    university_name: str = Field(..., description=\"Name of the university or institution\")\n",
        "    degree: str = Field(..., description=\"Degree earned by the candidate\")\n",
        "    gpa: Optional[str] = Field(None, description=\"GPA or grade, if available\")\n",
        "\n",
        "\n",
        "class Experience(BaseModel):\n",
        "    company_name: str = Field(..., description=\"Name of the company or organization\")\n",
        "    n_years: Optional[str] = Field(None, description=\"Duration in years at this company\")\n",
        "    project_name: Optional[str] = Field(None, description=\"Name or title of a key project\")\n",
        "    project_description: Optional[str] = Field(None, description=\"Brief description of the project\")\n",
        "    tech_stack: List[str] = Field(..., description=\"Technologies and tools used in the project\")\n",
        "\n",
        "    @field_validator(\"tech_stack\", mode=\"before\")\n",
        "    def handle_not_found_tech_stack(cls, v):\n",
        "        if isinstance(v, str) and v.strip().lower() == \"not found\":\n",
        "            return []\n",
        "        return v\n",
        "\n",
        "\n",
        "class ContactInfo(BaseModel):\n",
        "    email: Optional[str] = Field(None, description=\"Email address\")\n",
        "    phone: Optional[str] = Field(None, description=\"Phone number\")\n",
        "    linkedin: Optional[str] = Field(None, description=\"LinkedIn profile URL\")\n",
        "\n",
        "\n",
        "class ResumeReport(BaseModel):\n",
        "    name: str = Field(..., description=\"Full name of the candidate\")\n",
        "    # age: Optional[int] = Field(None, ge=0, description=\"Age of the candidate, if available\")\n",
        "    # native_languages: List[str] = Field(default_factory=list, description=\"List of native languages spoken by the candidate\")\n",
        "    # match_score: int = Field(..., ge=0, le=100, description=\"Match score between 0–100\")\n",
        "    # match_score: str = Field(..., description=\"Match score between 0–100\")\n",
        "    education: Optional[List[Education]] = Field(..., description=\"List of education details\")\n",
        "    experience: Optional[List[Experience]] = Field(..., description=\"List of professional experience\")\n",
        "    skills: Optional[List[str]] = Field(..., description=\"List of key skills and strengths\")\n",
        "    employment_gaps: Optional[str] = Field(None, description=\"Employment gaps if found\")\n",
        "    contact_info: ContactInfo = Field(..., description=\"Contact information\")\n",
        "    summary: str = Field(..., description=\"Short summary about the candidate's fit for the job\")\n",
        "\n",
        "    @field_validator(\"skills\", mode=\"before\")\n",
        "    def convert_skills_not_found(cls, v):\n",
        "        if isinstance(v, str) and v.strip().lower() == \"not found\":\n",
        "            return []\n",
        "        return v\n",
        "\n",
        "    @field_validator(\"education\", \"experience\", mode=\"before\")\n",
        "    def convert_list_fields_not_found(cls, v):\n",
        "        if isinstance(v, str) and v.strip().lower() == \"not found\":\n",
        "            return []\n",
        "        return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa8arGFQIDFx"
      },
      "outputs": [],
      "source": [
        "def get_metadata(doc):\n",
        "  distance = round(float(doc.metadata['distance']),4)\n",
        "  score = round(float(doc.metadata['score_percent']),4)\n",
        "  source = doc.metadata['source']\n",
        "  return {\n",
        "      'distance': distance,\n",
        "      'score': score,\n",
        "      'source': source\n",
        "  }\n",
        "\n",
        "def extract_years_from_text(text: str) -> float:\n",
        "    \"\"\"\n",
        "    Extracts a numeric value (float/int) from a string and converts months to years if needed.\n",
        "\n",
        "    Args:\n",
        "        text (str): e.g., '6-12 months', '0.5 years', '1 year'\n",
        "\n",
        "    Returns:\n",
        "        float: Duration in years\n",
        "    \"\"\"\n",
        "    match = re.search(r\"\\d+(\\.\\d+)?\", text)\n",
        "    if not match:\n",
        "        return 0.0\n",
        "\n",
        "    value = float(match.group())\n",
        "\n",
        "    if 'month' in text.lower():\n",
        "        return round(value / 12, 2)\n",
        "    else:\n",
        "        return round(value, 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u31FTow7IJg5"
      },
      "outputs": [],
      "source": [
        "def get_all_cv_results(retriever_docs, main_chain, job_description):\n",
        "  RESULTS = []\n",
        "  for retriever in retriever_docs:\n",
        "    res = main_chain.invoke({\"job_description\": job_description, \"resume\": retriever.page_content}).dict()\n",
        "    metadata = get_metadata(retriever)\n",
        "    res['metadata'] = metadata\n",
        "    res['label'] = label_score_by_distance(metadata['distance'])\n",
        "    res['match_score'] = metadata['score']\n",
        "    total = 0\n",
        "    for exp in res['experience']:\n",
        "      yrs = extract_years_from_text(exp['n_years'])\n",
        "      total += yrs\n",
        "    res['total_experience'] = total\n",
        "    RESULTS.append(res)\n",
        "  return RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13v2VlTkIgvv"
      },
      "outputs": [],
      "source": [
        "  def get_results(directory_path, job_description):\n",
        "      docs = get_files(directory_path)\n",
        "      merged_docs = merge_pages(docs)\n",
        "      vector_store = get_embedding(merged_docs)\n",
        "      retriever_chain = ret_chain(vector_store)\n",
        "\n",
        "      llm = ChatGroq(temperature = 0, model=\"llama3-8b-8192\",\n",
        "                    groq_api_key=\"GROQ_API_KEY\")\n",
        "\n",
        "      retriever = retriever_chain.invoke(job_description)\n",
        "\n",
        "      resume_parser = PydanticOutputParser(pydantic_object=ResumeReport)\n",
        "\n",
        "      resume_prompt = PromptTemplate(\n",
        "      template=\"\"\"\n",
        "          You are a smart and precise Resume Analyzer.\n",
        "\n",
        "          You are given a **Job Description** and a candidate's **Resume** (plain text).\n",
        "          Your task is to analyze how well the resume matches the job requirements and return a structured report as a VALID JSON object.\n",
        "\n",
        "          ONLY use the resume content for your answers.\n",
        "          If any information is missing from the resume, write \"Not Found\".\n",
        "\n",
        "          ---\n",
        "\n",
        "          Job Description:\n",
        "          {job_description}\n",
        "\n",
        "          Resume:\n",
        "          {resume}\n",
        "\n",
        "          ---\n",
        "\n",
        "          Return ONLY a JSON object in the format below:\n",
        "          {format_instructions}\n",
        "          \"\"\",\n",
        "              input_variables=[\"job_description\", \"resume\"],\n",
        "              partial_variables={\"format_instructions\": resume_parser.get_format_instructions()}\n",
        "          )\n",
        "\n",
        "      main_chain =  resume_prompt | llm | resume_parser\n",
        "\n",
        "      RESULTS = get_all_cv_results(retriever, main_chain, job_description)\n",
        "\n",
        "      return RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQcdbsTpJRAb",
        "outputId": "ee352acb-521f-4d2f-b43f-b8ac181f8d4a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 45.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of the Merge data 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-41-1386176070.py:4: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  res = main_chain.invoke({\"job_description\": job_description, \"resume\": retriever.page_content}).dict()\n",
            "/tmp/ipython-input-41-1386176070.py:4: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  res = main_chain.invoke({\"job_description\": job_description, \"resume\": retriever.page_content}).dict()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'name': 'Muhammad Talha', 'education': [{'university_name': 'National Textile University', 'degree': 'Bachelor of Software Engineering', 'gpa': '3.52'}], 'experience': [{'company_name': 'Freelance', 'n_years': 'Present', 'project_name': 'Document Classifier', 'project_description': 'Automated classification of title closing documents using BERT model', 'tech_stack': ['TensorFlow', 'AWS Lambda', 'API Gateway']}, {'company_name': 'TransData', 'n_years': '1 year 3 months', 'project_name': 'Document Classifier', 'project_description': \"Developed and implemented the 'Document Classifier' at TransData, an advanced AI system for automating the classification of title closing documents in the mortgage and lending industry\", 'tech_stack': ['TensorFlow', 'AWS Lambda', 'API Gateway']}, {'company_name': 'BLING', 'n_years': '6 months', 'project_name': 'Message Spam Detection and Sentiment Analysis', 'project_description': 'Contributed to projects related to message spam detection and sentiment analysis, and developed a GPT-powered chatbot to improve user experiences', 'tech_stack': ['TensorFlow', 'AWS Lambda', 'API Gateway']}, {'company_name': 'HAWKLOGIX', 'n_years': '6 months', 'project_name': 'TeleStroke Evaluation Project', 'project_description': \"Worked on the TeleStroke evaluation project aimed at improving the hospital's response time to emergency stroke care and enhancing patient outcomes\", 'tech_stack': ['TensorFlow', 'AWS Lambda', 'API Gateway']}, {'company_name': 'Fiver', 'n_years': '1 year 2 months', 'project_name': 'Machine Learning, Deep Learning, and NLP Projects', 'project_description': 'Completed diverse freelance projects encompassing Machine Learning, Deep Learning, and NLP, involving tasks such as Classification, Regression, CNN, and Transfer Learning', 'tech_stack': ['TensorFlow', 'Keras', 'scikit-learn']}], 'skills': ['Machine Learning', 'Data Analysis', 'Deep Learning', 'Computer Vision', 'Natural Language Processing', 'Web Development', 'Desktop Application', 'MLops'], 'employment_gaps': None, 'contact_info': {'email': 'muhammadtalha1818@gmail.com', 'phone': '+923444300394', 'linkedin': 'https://www.linkedin.com/in/muhammad-talha-b643641b2/'}, 'summary': 'Highly experienced in the domains of machine learning, deep learning, and natural language processing (NLP), I am a passionate engineer and thriving analyst.', 'metadata': {'distance': 0.8122, 'score': 55.18, 'source': '/content/drive/MyDrive/Resume CV_Uploaded/Muhammad_Talha_-_ML_Engineer.pdf'}, 'label': 'Moderate match', 'match_score': 55.18, 'total_experience': 1.1600000000000001}, {'name': 'MUHAMMAD ANIS FASEEL', 'education': [{'university_name': 'University of South Asia, Lahore', 'degree': 'Bachelor of Software Engineering', 'gpa': '3.00/4.00'}], 'experience': [{'company_name': 'Self-Initiated Projects', 'n_years': 'Not Found', 'project_name': 'Laptop Price Prediction Model', 'project_description': 'Developed a Machine Learning model to predict laptop prices based on features such as brand, specifications, and other relevant attributes.', 'tech_stack': ['Python', 'pandas', 'scikit-learn']}, {'company_name': 'Self-Initiated Projects', 'n_years': 'Not Found', 'project_name': 'Healthcare Diagnosis Prediction Model', 'project_description': 'Developed a Healthcare Diagnosis Prediction Model using Python, Scikit-learn and Streamlit.', 'tech_stack': ['Python', 'Scikit-learn', 'Streamlit']}, {'company_name': 'Freelancing Projects', 'n_years': 'Not Found', 'project_name': 'Generative AI-based chatbot for WhatsApp', 'project_description': 'Developed a Generative AI-based chatbot for WhatsApp using Langchain Large Language Model (LLM)', 'tech_stack': ['Langchain', 'LLM']}, {'company_name': 'Freelancing Projects', 'n_years': 'Not Found', 'project_name': 'Medical AI chatbot', 'project_description': 'Build a Medical AI chatbot using Langchain Model Groq', 'tech_stack': ['Langchain', 'Groq']}], 'skills': ['Generative AI', 'Machine Learning', 'Deep Learning', 'NLP'], 'employment_gaps': None, 'contact_info': {'email': 'malikanas4737@gmail.com', 'phone': '+923166461053', 'linkedin': 'Not Found'}, 'summary': 'AI engineer with hands-on experience in Generative AI, Machine Learning, and Data Analysis.', 'metadata': {'distance': 1.0823, 'score': 48.02, 'source': '/content/drive/MyDrive/Resume CV_Uploaded/Resume By Anis Faseel.pdf'}, 'label': 'Moderate match', 'match_score': 48.02, 'total_experience': 0.0}, {'name': 'John Doe', 'education': [{'university_name': 'University of California', 'degree': 'BSc in Computer Science', 'gpa': 'Not Found'}], 'experience': [{'company_name': 'XYZ Technologies', 'n_years': '2', 'project_name': 'Not Found', 'project_description': 'Not Found', 'tech_stack': ['Selenium', 'TestNG', 'JUnit', 'Postman', 'JIRA']}, {'company_name': 'ABC Solutions', 'n_years': '2', 'project_name': 'Not Found', 'project_description': 'Not Found', 'tech_stack': ['MySQL', 'Oracle DB', 'REST APIs']}, {'company_name': 'Freelance QA Consultant', 'n_years': '1', 'project_name': 'Not Found', 'project_description': 'Not Found', 'tech_stack': ['Postman', 'Newman']}], 'skills': ['Manual Testing', 'Automation Testing', 'Test Plan Creation', 'Test Case Design', 'Bug Reporting'], 'employment_gaps': 'Not Found', 'contact_info': {'email': 'Not Found', 'phone': 'Not Found', 'linkedin': 'Not Found'}, 'summary': 'Detail-oriented Software Testing Engineer with over 5 years of experience in manual and automated testing.', 'metadata': {'distance': 1.4443, 'score': 40.91, 'source': '/content/drive/MyDrive/Resume CV_Uploaded/Sample_Software_Tester_CV.pdf'}, 'label': 'Weak match', 'match_score': 40.91, 'total_experience': 5.0}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-41-1386176070.py:4: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  res = main_chain.invoke({\"job_description\": job_description, \"resume\": retriever.page_content}).dict()\n"
          ]
        }
      ],
      "source": [
        "  directory_path = \"/content/drive/MyDrive/Resume CV_Uploaded\"\n",
        "  job_description = '''\n",
        "            Job Title: Data Scientist\n",
        "            We are seeking a Data Scientist with a strong foundation in data analysis, machine learning, and statistical modeling. The ideal candidate will be responsible for extracting insights from complex datasets, building predictive models, and communicating findings that drive business decisions.\n",
        "\n",
        "            Key Responsibilities\n",
        "            Analyze large datasets to discover trends, patterns, and actionable insights.\n",
        "\n",
        "            Build and deploy machine learning models for classification, regression, and clustering tasks.\n",
        "\n",
        "    '''\n",
        "  res = get_results(directory_path, job_description)\n",
        "  print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6egSm8pgJgq1",
        "outputId": "7ba0adab-e175-4745-8179-d41fcddcec76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'name': 'Muhammad Talha', 'education': [{'university_name': 'National Textile University', 'degree': 'Bachelor of Software Engineering', 'gpa': '3.52'}], 'experience': [{'company_name': 'Freelance', 'n_years': 'Present', 'project_name': 'Document Classifier', 'project_description': 'Automated classification of title closing documents using BERT model', 'tech_stack': ['TensorFlow', 'AWS Lambda', 'API Gateway']}, {'company_name': 'TransData', 'n_years': '1 year 3 months', 'project_name': 'Document Classifier', 'project_description': \"Developed and implemented the 'Document Classifier' at TransData, an advanced AI system for automating the classification of title closing documents in the mortgage and lending industry\", 'tech_stack': ['TensorFlow', 'AWS Lambda', 'API Gateway']}, {'company_name': 'BLING', 'n_years': '6 months', 'project_name': 'Message Spam Detection and Sentiment Analysis', 'project_description': 'Contributed to projects related to message spam detection and sentiment analysis, and developed a GPT-powered chatbot to improve user experiences', 'tech_stack': ['TensorFlow', 'AWS Lambda', 'API Gateway']}, {'company_name': 'HAWKLOGIX', 'n_years': '6 months', 'project_name': 'TeleStroke Evaluation Project', 'project_description': \"Worked on the TeleStroke evaluation project aimed at improving the hospital's response time to emergency stroke care and enhancing patient outcomes\", 'tech_stack': ['TensorFlow', 'AWS Lambda', 'API Gateway']}, {'company_name': 'Fiver', 'n_years': '1 year 2 months', 'project_name': 'Machine Learning, Deep Learning, and NLP Projects', 'project_description': 'Completed diverse freelance projects encompassing Machine Learning, Deep Learning, and NLP, involving tasks such as Classification, Regression, CNN, and Transfer Learning', 'tech_stack': ['TensorFlow', 'Keras', 'scikit-learn']}], 'skills': ['Machine Learning', 'Data Analysis', 'Deep Learning', 'Computer Vision', 'Natural Language Processing', 'Web Development', 'Desktop Application', 'MLops'], 'employment_gaps': None, 'contact_info': {'email': 'muhammadtalha1818@gmail.com', 'phone': '+923444300394', 'linkedin': 'https://www.linkedin.com/in/muhammad-talha-b643641b2/'}, 'summary': 'Highly experienced in the domains of machine learning, deep learning, and natural language processing (NLP), I am a passionate engineer and thriving analyst.', 'metadata': {'distance': 0.8122, 'score': 55.18, 'source': '/content/drive/MyDrive/Resume CV_Uploaded/Muhammad_Talha_-_ML_Engineer.pdf'}, 'label': 'Moderate match', 'match_score': 55.18, 'total_experience': 1.1600000000000001}, {'name': 'MUHAMMAD ANIS FASEEL', 'education': [{'university_name': 'University of South Asia, Lahore', 'degree': 'Bachelor of Software Engineering', 'gpa': '3.00/4.00'}], 'experience': [{'company_name': 'Self-Initiated Projects', 'n_years': 'Not Found', 'project_name': 'Laptop Price Prediction Model', 'project_description': 'Developed a Machine Learning model to predict laptop prices based on features such as brand, specifications, and other relevant attributes.', 'tech_stack': ['Python', 'pandas', 'scikit-learn']}, {'company_name': 'Self-Initiated Projects', 'n_years': 'Not Found', 'project_name': 'Healthcare Diagnosis Prediction Model', 'project_description': 'Developed a Healthcare Diagnosis Prediction Model using Python, Scikit-learn and Streamlit.', 'tech_stack': ['Python', 'Scikit-learn', 'Streamlit']}, {'company_name': 'Freelancing Projects', 'n_years': 'Not Found', 'project_name': 'Generative AI-based chatbot for WhatsApp', 'project_description': 'Developed a Generative AI-based chatbot for WhatsApp using Langchain Large Language Model (LLM)', 'tech_stack': ['Langchain', 'LLM']}, {'company_name': 'Freelancing Projects', 'n_years': 'Not Found', 'project_name': 'Medical AI chatbot', 'project_description': 'Build a Medical AI chatbot using Langchain Model Groq', 'tech_stack': ['Langchain', 'Groq']}], 'skills': ['Generative AI', 'Machine Learning', 'Deep Learning', 'NLP'], 'employment_gaps': None, 'contact_info': {'email': 'malikanas4737@gmail.com', 'phone': '+923166461053', 'linkedin': 'Not Found'}, 'summary': 'AI engineer with hands-on experience in Generative AI, Machine Learning, and Data Analysis.', 'metadata': {'distance': 1.0823, 'score': 48.02, 'source': '/content/drive/MyDrive/Resume CV_Uploaded/Resume By Anis Faseel.pdf'}, 'label': 'Moderate match', 'match_score': 48.02, 'total_experience': 0.0}, {'name': 'John Doe', 'education': [{'university_name': 'University of California', 'degree': 'BSc in Computer Science', 'gpa': 'Not Found'}], 'experience': [{'company_name': 'XYZ Technologies', 'n_years': '2', 'project_name': 'Not Found', 'project_description': 'Not Found', 'tech_stack': ['Selenium', 'TestNG', 'JUnit', 'Postman', 'JIRA']}, {'company_name': 'ABC Solutions', 'n_years': '2', 'project_name': 'Not Found', 'project_description': 'Not Found', 'tech_stack': ['MySQL', 'Oracle DB', 'REST APIs']}, {'company_name': 'Freelance QA Consultant', 'n_years': '1', 'project_name': 'Not Found', 'project_description': 'Not Found', 'tech_stack': ['Postman', 'Newman']}], 'skills': ['Manual Testing', 'Automation Testing', 'Test Plan Creation', 'Test Case Design', 'Bug Reporting'], 'employment_gaps': 'Not Found', 'contact_info': {'email': 'Not Found', 'phone': 'Not Found', 'linkedin': 'Not Found'}, 'summary': 'Detail-oriented Software Testing Engineer with over 5 years of experience in manual and automated testing.', 'metadata': {'distance': 1.4443, 'score': 40.91, 'source': '/content/drive/MyDrive/Resume CV_Uploaded/Sample_Software_Tester_CV.pdf'}, 'label': 'Weak match', 'match_score': 40.91, 'total_experience': 5.0}]\n"
          ]
        }
      ],
      "source": [
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZedlPhmrNbOX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptIX4yaqNgK-"
      },
      "outputs": [],
      "source": [
        "df=pd.DataFrame(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "GPNBEdUMNiih",
        "outputId": "b851af12-fe42-4b6b-c054-962bdbf2804a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Muhammad Talha\",\n          \"MUHAMMAD ANIS FASEEL\",\n          \"John Doe\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"experience\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"skills\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"employment_gaps\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Not Found\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contact_info\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Highly experienced in the domains of machine learning, deep learning, and natural language processing (NLP), I am a passionate engineer and thriving analyst.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metadata\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Weak match\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"match_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.1350145993777305,\n        \"min\": 40.91,\n        \"max\": 55.18,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          55.18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_experience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.6169702583967847,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.1600000000000001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-635e20d6-6b41-454a-ba43-846265ef3e17\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>education</th>\n",
              "      <th>experience</th>\n",
              "      <th>skills</th>\n",
              "      <th>employment_gaps</th>\n",
              "      <th>contact_info</th>\n",
              "      <th>summary</th>\n",
              "      <th>metadata</th>\n",
              "      <th>label</th>\n",
              "      <th>match_score</th>\n",
              "      <th>total_experience</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Muhammad Talha</td>\n",
              "      <td>[{'university_name': 'National Textile Univers...</td>\n",
              "      <td>[{'company_name': 'Freelance', 'n_years': 'Pre...</td>\n",
              "      <td>[Machine Learning, Data Analysis, Deep Learnin...</td>\n",
              "      <td>None</td>\n",
              "      <td>{'email': 'muhammadtalha1818@gmail.com', 'phon...</td>\n",
              "      <td>Highly experienced in the domains of machine l...</td>\n",
              "      <td>{'distance': 0.8122, 'score': 55.18, 'source':...</td>\n",
              "      <td>Moderate match</td>\n",
              "      <td>55.18</td>\n",
              "      <td>1.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MUHAMMAD ANIS FASEEL</td>\n",
              "      <td>[{'university_name': 'University of South Asia...</td>\n",
              "      <td>[{'company_name': 'Self-Initiated Projects', '...</td>\n",
              "      <td>[Generative AI, Machine Learning, Deep Learnin...</td>\n",
              "      <td>None</td>\n",
              "      <td>{'email': 'malikanas4737@gmail.com', 'phone': ...</td>\n",
              "      <td>AI engineer with hands-on experience in Genera...</td>\n",
              "      <td>{'distance': 1.0823, 'score': 48.02, 'source':...</td>\n",
              "      <td>Moderate match</td>\n",
              "      <td>48.02</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>John Doe</td>\n",
              "      <td>[{'university_name': 'University of California...</td>\n",
              "      <td>[{'company_name': 'XYZ Technologies', 'n_years...</td>\n",
              "      <td>[Manual Testing, Automation Testing, Test Plan...</td>\n",
              "      <td>Not Found</td>\n",
              "      <td>{'email': 'Not Found', 'phone': 'Not Found', '...</td>\n",
              "      <td>Detail-oriented Software Testing Engineer with...</td>\n",
              "      <td>{'distance': 1.4443, 'score': 40.91, 'source':...</td>\n",
              "      <td>Weak match</td>\n",
              "      <td>40.91</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-635e20d6-6b41-454a-ba43-846265ef3e17')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-635e20d6-6b41-454a-ba43-846265ef3e17 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-635e20d6-6b41-454a-ba43-846265ef3e17');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d9577a06-3bef-4a1a-baf6-cec5515ece85\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d9577a06-3bef-4a1a-baf6-cec5515ece85')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d9577a06-3bef-4a1a-baf6-cec5515ece85 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_917574c3-1871-4b56-9c61-236ac1347530\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_917574c3-1871-4b56-9c61-236ac1347530 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                   name                                          education  \\\n",
              "0        Muhammad Talha  [{'university_name': 'National Textile Univers...   \n",
              "1  MUHAMMAD ANIS FASEEL  [{'university_name': 'University of South Asia...   \n",
              "2              John Doe  [{'university_name': 'University of California...   \n",
              "\n",
              "                                          experience  \\\n",
              "0  [{'company_name': 'Freelance', 'n_years': 'Pre...   \n",
              "1  [{'company_name': 'Self-Initiated Projects', '...   \n",
              "2  [{'company_name': 'XYZ Technologies', 'n_years...   \n",
              "\n",
              "                                              skills employment_gaps  \\\n",
              "0  [Machine Learning, Data Analysis, Deep Learnin...            None   \n",
              "1  [Generative AI, Machine Learning, Deep Learnin...            None   \n",
              "2  [Manual Testing, Automation Testing, Test Plan...       Not Found   \n",
              "\n",
              "                                        contact_info  \\\n",
              "0  {'email': 'muhammadtalha1818@gmail.com', 'phon...   \n",
              "1  {'email': 'malikanas4737@gmail.com', 'phone': ...   \n",
              "2  {'email': 'Not Found', 'phone': 'Not Found', '...   \n",
              "\n",
              "                                             summary  \\\n",
              "0  Highly experienced in the domains of machine l...   \n",
              "1  AI engineer with hands-on experience in Genera...   \n",
              "2  Detail-oriented Software Testing Engineer with...   \n",
              "\n",
              "                                            metadata           label  \\\n",
              "0  {'distance': 0.8122, 'score': 55.18, 'source':...  Moderate match   \n",
              "1  {'distance': 1.0823, 'score': 48.02, 'source':...  Moderate match   \n",
              "2  {'distance': 1.4443, 'score': 40.91, 'source':...      Weak match   \n",
              "\n",
              "   match_score  total_experience  \n",
              "0        55.18              1.16  \n",
              "1        48.02              0.00  \n",
              "2        40.91              5.00  "
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a2EuROnNi3o"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
